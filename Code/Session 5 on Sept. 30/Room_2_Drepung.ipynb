{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Room_2_Drepung.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3Yo5f69B4KZf"},"source":["# List Full Names of all the participants in your team below:\n","1. \n","2. \n","3. \n","4. \n","5. \n","6. \n","7. \n","8.  \n","9. \n","10. \n","11. \n"]},{"cell_type":"markdown","metadata":{"id":"MNouPPtu4KLq"},"source":["Hello Machine Learning Engineer Drepung Team, \n","\n","You have been given a data which is obtained from **COVID-19 Tracking project** and NYTimes. Coronaviruses are a large family of viruses which may cause illness in animals or humans. In humans, several coronaviruses are known to cause respiratory infections ranging from the common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS). \n","\n","The number of new cases are increasing day by day around the world. This dataset has COVID information for United States at daily level.\n","\n","Number of Instances: 156 <br>\n","Number of Attributes: 7 (including the target variable `y`)\n","\n","Attribute Information: \n","   * **y:**  Total number of tests with positive results in a single day(Numerical)\n","   * **f1:** date of observation\n","   * **f2:** number of tests with negative results (Numerical)\n","   * **f2:** number of test with pending results (Numerical)\n","   * **f3:** Number of patients hospitalized on the date (Numerical)\n","   * **f4:** Number of patients on ventilator on the date (Numerical)\n","   * **f5:** Number of patients recovered on the date (Numerical)\n","   * **f6:** number of deaths (Numerical)\n","\n","There are no missing Attribute Values.\n","\n","Your task is to implement a **Linear Regression model using Gradient Descent Solution** for predicting the total number of positive results in a single day\n","\n","## Gradient Descent Solution\n","The **genesis equation** for Linear Regression is of the form:\n","\n","$y(x,w) = W.x + b$  \n","\n","* $y(x,w)$ is predicted output,\n","* $x$ is the Input\n","* $W = [W_{1}, W_{2}, .. , W_{F}]$ are the parameters to be learned from training samples with $F$ Features\n","* $b$ is the bias\n","\n","\n","\n","YOU NEED TO IMPLEMENT an iterative solution to solve for $W$ (Gradient Descent Solution) \n","\n","<font color=\"red\">DO NOT USE SKLEARNS LINEAR REGRESSION LIBRARY DIRECTLY.</font>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"91CypY474KBm"},"source":["### **Question:** In the following code cell implement the following:\n","* Step 1: Import the dataset (us_covid.csv) using Pandas Dataframe (Step 1 Implemented already)\n","* Step 2: Partition your dataset into training testing and validation using sklearns train_test_split library and split the features and target labels into seperate variables (Step 2 Implemented already)\n","* Step 3: Scale the features using sklearns min max scaling function (Step 3 Implemented already)\n","* Step 4: Convert Scaled Features and Labels into numpy arrays with dimensions required by closed form solution (Step 4 Implemented already)\n","* Step 5: Initialize the learning rate, number of epochs, weight vector, bias scalar and other variables required for tracking cost.\n","* Step 6: Train with Training Dataset using Gradient Descent Solution\n","  Iteratively update the weights and biases for each epoch using:\n","  * Step 6.1: Use genesis equation $\\hat{y} = W^{T}.X + b$ where $W$ is the weight array, $X$ is the input features and $\\hat{y}$ is the predicted value. (You will have to perform same operation on validation set as well)\n","  * Step 6.2: Find Mean Squared Error (MSE) Loss Function (L) for training and validation set using predicted value $\\hat{y}$ and truth value $y$\n","    * MSE Train Cost = $\\frac{1}{n} \\sum_{i=1}^{i=n} (y\\_train_{i} - \\hat{y}\\_train_{i})^{2}$\n","  * Step 6.3: Find $ \\Delta W_{j} = \\frac{\\delta L}{\\delta W_{j}}$ and $ \\Delta b = \\frac{\\delta L}{\\delta b}$ where $j = 1$ to $F$(Proof for finding  $\\Delta W$ and $\\Delta b$ is available in the appendix below)\n","    * $ \\Delta W_{j} = \\frac{\\delta L}{\\delta W_{j}} = \\frac{2}{n}\\sum_{i=1}^{i=n}(y\\_train_{i} - \\hat{y}\\_train_{i})*x_{ij}$\n","    * $ \\Delta b = \\frac{\\delta L}{\\delta b} = \\frac{2}{n}\\sum_{i=1}^{i=n}(y\\_train_{i} - \\hat{y}\\_train_{i})$\n","  * Step 6.4: Update $W$ and $b$ using learning rate($\\eta$) as follows:\n","    - $W_{j} = W_{j} - \\eta*\\Delta W_{j}$\n","    - $b = b - \\eta*\\Delta b$\n","  * Step 6.5: Store MSE Cost for training and validation in cost tracking lists\n","* Step 7: Plot validation and training cost vs number of epochs (Already Implemented)\n","* Step 8: Test using Testing Dataset\n","  * Step 8.1: Use genesis equation $\\hat{y} = W^{T}.X_{test} + b$ where $W$ is the weight array, $X_{test}$ is the input test features and $\\hat{y}$ is the predicted value.\n","  * Step 8.2: Calculate Mean Squared Error (MSE) for Test Dataset\n","    * MSE Test Cost$ = \\frac{1}{n}\\sum_{i=1}^{i=n} (y\\_test_{i} - \\hat{y}\\_test_{i})^{2}$ "]},{"cell_type":"markdown","metadata":{"id":"x307J4A7Ueja"},"source":["## TA Response"]},{"cell_type":"code","metadata":{"id":"ZtfUEE-RUeUH","executionInfo":{"status":"ok","timestamp":1601910757101,"user_tz":240,"elapsed":1696,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}}},"source":["# Step 1 already implemented\n","import pandas as pd\n","import io\n","import requests\n","url=\"https://raw.githubusercontent.com/Mihir2/BreakoutSessionDataset/master/AirQualitySeattle.csv\"\n","s = requests.get(url).content\n","data = pd.read_csv(io.StringIO(s.decode('utf-8')))\n","data\n","\n","# Step 2 already implemented\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","output = data['y']\n","input = data.to_numpy()[:,1:]\n","x_train, x_val_test, y_train, y_val_test = train_test_split(input, output, test_size = 0.8)\n","x_val, x_test, y_val, y_test = train_test_split(input, output, test_size = 0.5)\n","\n","# Step 3 already implemented\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","sc_xtrain = scaler.fit_transform(x_train)\n","sc_xval = scaler.fit_transform(x_val)\n","sc_xtest = scaler.transform(x_test)\n","\n","# Step 4 already implemented\n","y_train_arr = y_train.to_numpy().reshape(y_train.shape[0],1).T\n","x_train_arr = sc_xtrain.T\n","y_val_arr = y_val.to_numpy().reshape(y_val.shape[0],1).T\n","x_val_arr = sc_xval.T\n","y_test_arr  = y_test.to_numpy().reshape(y_test.shape[0],1).T\n","x_test_arr  = sc_xtest.T\n","\n","# Step 5 already implemented\n","learningrate = 0.005\n","epochs = 1000\n","bias = 0\n","\n","number_of_features         = x_train_arr.shape[0]\n","number_of_train_datapoints = x_train_arr.shape[1]\n","number_of_val_datapoints   = x_val_arr.shape[1]\n","number_of_test_datapoints  = x_test_arr.shape[1]\n","\n","weights = np.random.randn(number_of_features,1)\n","\n","training_cost_track = []\n","val_cost_track = []\n","\n","# Step 6\n","for epoch in range(epochs):\n","    \n","    # Step 6.1 y_pred = wT.X + b (For Training and Validation dataset)\n","    train_pred = np.dot(weights.T, x_train_arr) + bias\n","    val_pred   = np.dot(weights.T, x_val_arr)   + bias\n","    \n","    # Step 6.2 MSE Cost for Training and Validation Dataset\n","    train_cost = np.sum((train_pred - y_train_arr)**2)/number_of_train_datapoints\n","    val_cost   = np.sum((val_pred - y_val_arr)**2)/number_of_val_datapoints\n","    \n","    # Step 6.3: Calculate derivatives\n","    dz = train_pred - y_train_arr\n","    dw = (1/number_of_train_datapoints) * np.dot(x_train_arr, dz.T)\n","    db = (1/number_of_train_datapoints) * np.sum(dz)\n","    \n","    # Step 6.4: update weights and bias\n","    weights = weights - learningrate * dw\n","    bias = bias - learningrate * db\n","\n","    # Step 6.5: Store MSE Cost for training and validation in seperate cost tracking list\n","    training_cost_track.append(train_cost)\n","    val_cost_track.append(val_cost)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcRpRcU0Ulzc","executionInfo":{"status":"ok","timestamp":1601910764989,"user_tz":240,"elapsed":873,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}}},"source":["# Step 8.1: Test using Testing Dataset: Get the predicted values \n","test_pred = np.dot(weights.T, x_test_arr) + bias\n","\n","# Step 8.2: Calculate the MSE for Testing dataset\n","test_cost = np.sum((test_pred - y_test_arr)**2)/number_of_test_datapoints"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hPRdpinGUe_1"},"source":["## Student Response"]},{"cell_type":"code","metadata":{"id":"65I7h1OH3tw0","executionInfo":{"status":"error","timestamp":1601775208072,"user_tz":240,"elapsed":885,"user":{"displayName":"Daniel Ip","photoUrl":"","userId":"00274679789624241712"}},"outputId":"8ddd2f2d-cdb8-40dc-ed49-33a1368d0f8a","colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["# Step 1 already implemented\n","import pandas as pd\n","import io\n","import requests\n","url=\"https://raw.githubusercontent.com/Mihir2/BreakoutSessionDataset/master/us_covid.csv\"\n","s = requests.get(url).content\n","data = pd.read_csv(io.StringIO(s.decode('utf-8')))\n","data\n","\n","# Step 2 already implemented\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","output = data['y']\n","input = data.to_numpy()[:,1:]\n","x_train, x_val_test, y_train, y_val_test = train_test_split(input, output, test_size = 0.8)\n","x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size = 0.5)\n","\n","# Step 3 already implemented\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","sc_xtrain = scaler.fit_transform(x_train)\n","sc_xval = scaler.fit_transform(x_val)\n","sc_xtest = scaler.transform(x_test)\n","\n","# Step 4 already implemented\n","y_train_arr = y_train.to_numpy().reshape(y_train.shape[0],1).T\n","x_train_arr = sc_xtrain.T\n","y_val_arr = y_val.to_numpy().reshape(y_val.shape[0],1).T\n","x_val_arr = sc_xval.T\n","y_test_arr  = y_test.to_numpy().reshape(y_test.shape[0],1).T\n","x_test_arr  = sc_xtest.T\n","\n","# Step 5 already implemented\n","learningrate = 0.005\n","epochs = 1000\n","bias = 0\n","\n","number_of_features         = x_train_arr.shape[0]\n","number_of_train_datapoints = x_train_arr.shape[1]\n","number_of_val_datapoints   = x_val_arr.shape[1]\n","number_of_test_datapoints  = x_test_arr.shape[1]\n","\n","weights = np.random.randn(number_of_features,1)\n","\n","training_cost_track = []\n","val_cost_track = []\n","\n","# Step 6\n","for epoch in range(epochs):\n","    \n","    # Step 6.1 y_pred = wT.X + b (For Training and Validation dataset)\n","    \n","    # Step 6.2 MSE Cost for Training and Validation Dataset\n","    \n","    # Step 6.3: Calculate derivatives\n"," \n","    # Step 6.4: update weights and bias\n","\n","    # Step 6.5: Store MSE Cost for training and validation in seperate cost tracking list"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-6b8f60e3eb2f>\"\u001b[0;36m, line \u001b[0;32m59\u001b[0m\n\u001b[0;31m    # Step 6.5: Store MSE Cost for training and validation in seperate cost tracking list\u001b[0m\n\u001b[0m                                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}]},{"cell_type":"code","metadata":{"id":"6c_ThlCsvbGN"},"source":["# Step 7: Plot MSE cost for training and validation set vs number of epochs (Already Implemented)\n","import matplotlib.pyplot as plt\n","plt.title('Training and Validation Loss With Learning Rate: ' + str(learningrate))\n","plt.plot(training_cost_track, color='red', label='Training Data')\n","plt.plot(val_cost_track, color='blue', label='Validation Data')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bljpCdHYvlHD"},"source":["# Step 8.1: Test using Testing Dataset: Get the predicted values \n","\n","# Step 8.2: Calculate the MSE for Testing dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f4w_S7u3vovk"},"source":["### Appendix (Proof)\n","\n","![!picture](https://drive.google.com/uc?export=view&id=1MVcYLfEzAlKcumhLiwrsmGSn0-AAK3tg)"]}]}