{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Room_3_Ganden.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fxi0ZgQ-4-ll","colab_type":"text"},"source":["# List Full Names of all the participants in your team below:\n","\n","1. Gaurav Toravane\n","2. Gurleen Kaur\n","3. Vinci Wu\n","4. Joseph McCart\n","5. Shuoling Li\n","6. Gowtham Rajasekaran\n","7. Mayank Lara\n","8. \n","9. \n","10.\n","11. \n","12. "]},{"cell_type":"markdown","metadata":{"id":"CqHGbY0o4-a2","colab_type":"text"},"source":["Hello Machine Learning Engineer Ganden Team, \n","\n","You have been given a data which is obtained from **Forest Fires** in California. \n","\n","Number of Instances: 517 <br>\n","Number of Attributes: 11 (including the target variable `y`)\n","\n","Attribute Information: \n","  * **y** area - the burned area of the forest in Calfornia(in ha): 0.00 to 1090.84\n","  * **f1** X - x-axis spatial coordinate within the California State Park: 1 to 9\n","  * **f2** Y - y-axis spatial coordinate within the California State Park: 2 to 9\n","  * **f3** FFMC - FFMC index from the FWI system: 18.7 to 96.20\n","  * **f4** DMC - DMC index from the FWI system: 1.1 to 291.3\n","  * **f5** DC - DC index from the FWI system: 7.9 to 860.6\n","  * **f6** ISI - ISI index from the FWI system: 0.0 to 56.10\n","  * **f7** temp - temperature in Celsius degrees: 2.2 to 33.30\n","  * **f8** RH - relative humidity in %: 15.0 to 100\n","  * **f9** wind - wind speed in km/h: 0.40 to 9.40\n","  * **f10** rain - outside rain in mm/m2 : 0.0 to 6.4\n","\n","There are no missing Attribute Values.\n","\n","Your task is to implement a **Gaussian Radial Basis Function based Linear Regression Algorithm** to predict the area burned during the Forest Fires in California.\n","\n","\n","# Closed Form Solution with Basis Functions\n","The **genesis equation** for Linear Regression with Gaussian Basis Function is of the form:\n","\n","$y(x,w) = \\phi(x).W$  \n","\n","* $y(x,w)$ is predicted output,\n","* $\\phi(x)$ is the Design Matrix\n","* $W = (w_{1}, ... w_{M})$ are the parameters to be learned from training samples\n","\n","### Design Matrix\n","Each gaussian radial basis function $\\phi_{j}$ converts the input instance to a value as shown below: <br>\n","\n","$\\phi_{j}(x) = \\exp(-\\frac{1}{2}(x - \\mu_{j})^{T}\\sum_{j}^{-1}(x - \\mu_{j}))$\n","\n","* $x$ is the input scaled dataset <br>\n","* $\\mu_{j}$ is the center of the $j_{th}$ Guassian Radial Basis Function <br>\n","* $\\sum_{j}$ decides how braodly the $j_{th}$ basis function spreads (Diagonal Covariance Matrix)\n","\n","Repeated application of $j$ basis functions results in a Design Matrix as shown below:\n","![!picture](https://drive.google.com/uc?export=view&id=1j1kxv6nUPPECacd-_bDg_lL1yTJS5BwA)\n","\n","For finding parameters $W$ for the above genesis using the **closed form solution** we pre-multiply by $\\phi^{-1}(x)$ on LHS and RHS. We get,\n","\n","$W = \\phi^{-1}(x)Y$\n","\n","But $\\phi(x)$ is NOT A SQUARE MATRIX of FULL RANK! Hence, $\\phi^{-1}(x)$ is intractable.\n","\n","We therefore use the Moore-Penrose pseudo inverse as a generalization of the matrix inverse when the matrix may not be invertible. Hence, the final closed form solution for finding parameters $W$ with linear regression least squares solution is as follows:\n","\n","$W = (\\phi^{T}\\phi)^{-1}\\phi^{T}Y$\n","\n","YOU NEED TO IMPLEMENT ABOVE EQUATION for finding $W$. \n","\n","<font color=\"red\"> YOU CANNOT USE NUMPY linalg **pinv** https://numpy.org/doc/stable/reference/generated/numpy.linalg.pinv.html </font>\n","\n","<font color=\"red\">DO NOT USE SKLEARNS LINEAR REGRESSION LIBRARY DIRECTLY.</font>\n","\n","<font color=\"green\">YOU CAN USE np.linalg.inv, and np.dot FOR IMPLEMENTING PSEUDO-INVERSE</font>"]},{"cell_type":"markdown","metadata":{"id":"EFACoKjf4-Wj","colab_type":"text"},"source":["### **Question:** In the following code cell implement the following:\n","* Step 1: Import the dataset (forestfires.csv) using Pandas Dataframe (Step 1 Implemented already)\n","* Step 2: Partition your dataset into training testing and validation using sklearns train_test_split library and split the features and target labels into seperate variables (Step 2 Implemented already)\n","* Step 3: Scale the features using sklearns min max scaling function (Step 3 Implemented already)\n","* Step 4: Convert Scaled Features and Labels into numpy arrays with dimensions required by closed form solution (Step 4 Implemented already)\n","* Step 5: Find the Mean ($\\mu_{j}$) and Spread ($\\sum_{j}$) for **3 basis functions** (Step 5 Implemented Already)\n","* Step 6: Create a Design Matrix using the scaled features, Mean ($\\mu_{j}$) and Spread ($\\sum_{j}$)\n","* Step 7: Train using Linear Regression algorithm with a Closed Form Solution **Hint: Use Pseudo Inverse Formula**\n","* Step 8: Test using Testing Dataset (Make sure you create a design matrix for Testing dataset using same Mean ($\\mu_{j}$) and Spread ($\\sum_{j}$) from Step 5)\n","* Step 9: Calculate Root Mean Squared Error (Erms) for Test Dataset\n","    * $Erms = \\sqrt{\\frac{1}{n}\\sum_{i=0}^{i=n} (y\\_test_{i} - y\\_test\\_pred_{i})^{2}}$ "]},{"cell_type":"code","metadata":{"id":"MGTpYQl93z_P","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600965709352,"user_tz":240,"elapsed":1540,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}}},"source":["# Step 1 already implemented\n","import pandas as pd\n","import io\n","import requests\n","url=\"https://raw.githubusercontent.com/Mihir2/BreakoutSessionDataset/master/forestfires.csv\"\n","s = requests.get(url).content\n","data = pd.read_csv(io.StringIO(s.decode('utf-8')))\n","data\n","\n","# Step 2 already implemented\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","output = data['y']\n","input = data.to_numpy()[:,1:]\n","x_train, x_test, y_train, y_test = train_test_split(input, output, test_size = 0.2)\n","\n","# Step 3 already implemented\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","sc_xtrain = scaler.fit_transform(x_train)\n","sc_xtest = scaler.transform(x_test)\n","\n","# Step 4 already implemented\n","y_train_arr = y_train.to_numpy().reshape(y_train.shape[0],1)\n","x_train_arr = sc_xtrain\n","y_test_arr  = y_test.to_numpy().reshape(y_test.shape[0],1)\n","x_test_arr  = sc_xtest\n","\n","# Step 5 already implemented\n","from  sklearn.cluster import MiniBatchKMeans\n","number_of_basis_function = 3\n","model = MiniBatchKMeans(n_clusters=number_of_basis_function)\n","distances = model.fit_transform(x_train_arr)\n","basis_means = model.cluster_centers_\n","basis_variances = np.zeros(number_of_basis_function)\n","i = 0\n","for label in model.labels_:\n","  basis_variances[label] = basis_variances[label] + (distances[i][label]**2)\n","  i = i + 1\n","for j in range(0,number_of_basis_function):\n","  basis_variances[j] = basis_variances[j]/np.count_nonzero(model.labels_ == j)\n","basis_variances = np.diag(basis_variances)\n","# print(basis_means)\n","# print(basis_variances)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"74Ei0qTK_qSb","colab_type":"text"},"source":["## TA Response:"]},{"cell_type":"code","metadata":{"id":"KOyylEd35LjN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600965921287,"user_tz":240,"elapsed":485,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}},"outputId":"f4b14e1f-5b27-48cc-f10a-e3ec89e7e0bd"},"source":["# Step 6\n","x_mu = np.zeros((number_of_basis_function,x_train_arr.shape[0]))\n","for i in range(0,number_of_basis_function):\n","  x_mu[i] = np.sum((x_train_arr - basis_means[i]),axis=1)\n","\n","train_design_mat = np.exp(-0.5*np.multiply(np.dot(x_mu.T,np.linalg.inv(basis_variances)),x_mu.T))\n","\n","# Step 7 \n","weights = np.dot(np.dot(np.linalg.inv(np.dot(train_design_mat.T,train_design_mat)),train_design_mat.T),y_train_arr)\n","\n","# Step 8\n","x_mu = np.zeros((number_of_basis_function,x_test_arr.shape[0]))\n","for i in range(0,number_of_basis_function):\n","  x_mu[i] = np.sum((x_test_arr - basis_means[i]),axis=1)\n","\n","test_design_mat = np.exp(-0.5*np.multiply(np.dot(x_mu.T,np.linalg.inv(basis_variances)),x_mu.T))\n","y_test_pred = np.dot(test_design_mat, weights)\n","\n","#Step 9\n","Erms = np.sqrt(np.sum((y_test_pred - y_test_arr)**2)/y_test_arr.shape[0])\n","print(Erms)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["30.385902712331177\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HQR3xH_a_dvG","colab_type":"text"},"source":["## Student Response:"]},{"cell_type":"code","metadata":{"id":"-I2-c7X7_czZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600965709358,"user_tz":240,"elapsed":1533,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}},"outputId":"d2abf3ee-9c20-49f5-feb2-67dcb56af82a"},"source":["# Step 6 \n","inv = np.linalg.inv(basis_variances)\n","design_matrix = np.zeros((413,3))\n","# print(inv.shape)\n","for i in range(number_of_basis_function):\n"," #  design_matrix[:,i] = np.exp((-0.5) * (x_train_arr - basis_means[i,:]) * (inv[i,i]))\n","  design_matrix[:,i] = np.exp(-0.5*np.sqrt(np.sum((x_train_arr - basis_means[i,:])**2, axis= 1))*inv[i,i])\n","# design_matrix.shape\n","# design_matrix[1:10]\n","\n","design_matrix_test = np.zeros(( x_test_arr.shape[0],number_of_basis_function))\n","for i in range(number_of_basis_function):\n","  # design_matrix[:,i] = np.exp((-0.5) * (x_train_arr - basis_means[i,:]) * (inv[i,i]))\n","  design_matrix_test[:,i] = np.exp(-0.5*np.sqrt(np.sum((x_test_arr - basis_means[i,:])**2, axis= 1))*inv[i,i])\n","\n","multiplied = np.dot(design_matrix.T,design_matrix)\n","W = np.dot(np.linalg.inv(multiplied), design_matrix.T)\n","W = np.dot(W,y_train_arr)\n","\n","# Step 7 \n","# print(W.shape)\n","# print(design_matrix_test.shape)\n","\n","# Step 8 \n","y_preds = np.dot(design_matrix_test, W)\n","\n","# Step 9 \n","from sklearn.metrics import mean_squared_error\n","\n","rmse = np.sqrt(mean_squared_error(y_test_arr,y_preds))\n","print(\"rmse :{}\".format(rmse))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["rmse :30.340528822983973\n"],"name":"stdout"}]}]}