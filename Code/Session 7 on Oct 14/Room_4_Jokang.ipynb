{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Room_4_Jokang.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6zleMtZ196Fz"},"source":["# List Full Names of all the participants in your team below:\n","1.  Arghya Dutta\n","2.  David\n","3. Hemant Kumar Das\n","4. Kapindran Kulandaivelu\n","5. Kevin Lin\n","6. Mohan Vellayan\n","7. Rishabh Kumar\n","8. Vineet Jain\n","9. Mohit Gokul Murali\n","10. \n","11. "]},{"cell_type":"markdown","metadata":{"id":"vkQkNyTy-v07"},"source":["Hello Machine Learning Engineer Jokang Team, \n","\n","You have been given a data which is obtained from **Breast Cancer Dataset**. The dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.\n","\n","Number of Instances: 306 <br>\n","Number of Attributes: 3 (including the target variable `y`)\n","\n","Attribute Information: \n","  * **y**: Survival status (class attribute) \n","      * -1 = the patient died within 5 year\n","      * 1 = the patient survived 5 years or longer\n","  * **f1**: Age of patient at time of operation (numerical)\n","  * **f2**: Patient's year of operation (year - 1900, numerical)\n","  * **f3**: Number of positive axillary nodes detected (numerical)\n","\n","There are no missing Attribute Values.\n","\n","Your task is to implement a **Iterative Reweighted Least Squares Approach for Logistic Regression** to predict if the patient survived within 5 years of contracting breast cancer.\n"]},{"cell_type":"markdown","metadata":{"id":"NzMtidBP-xAP"},"source":["\n","## Iterative reweighted least squares\n","The **Genesis Equation** for Logistic Regression Model is of the form:\n","\n","$\\hat{y}(x,w) = \\sigma (w^{T}.x)$  <br>\n","\n","* $\\hat{y}(x,w)$ is predicted output,\n","* $x$ is the aumented Input (augmented with unit vector column)\n","* $w = [w_{0}, w_{1}, w_{2}, .. , w_{F}]$ are the parameters to be learned from training samples with $F$ Features\n","* $t_{n}$ is the target variable (truth label)\n","\n","The **Loss Function** for Logistic Regression Model is of the form: <br>\n","\n","$E(w) = -\\Sigma_{n=1}^{N} [t_{n} \\log {\\hat{y}_{n}} + (1 - t_{n}) \\log {(1 - \\hat{y}_{n}})]$\n","\n","The **Newton-Raphson update**, for minimizing a function E(w), takes the form\n","\n","$w^{new} = w^{old} - H^{-1} \\Delta E(w) $ <br>\n","Where H is the Hessian matrix whose elements comprise the second derivative with respect to the components of w.\n","\n","Applying the Newton-Raphson update to the binary-cross-entropy error function\n","for the logistic regression model. We see that the gradient and\n","Hessian of this error function are given by: <br>\n","\n","$\\Delta E(w) = \\Sigma^{N}_{n = 1} (\\hat{y}_{n} - t_{n})x_{n} = x^{T} (\\hat{y} - t)$ <br>\n","\n","$H = \\Delta \\Delta E(w) = \\Sigma^{N}_{n = 1} \\hat{y}_{n}(1 - \\hat{y}_{n})x_{n}x_{n}^{T} = x^{T}Rx$\n","\n","Where $R$ is a NxN diagonal matrix with elements $R_{nn} = \\hat{y}_{n}(1 - \\hat{y}_{n})$\n","\n","The Newton-Raphson update formula for the logistic regression model then becomes: <br>\n","$w^{new} = w^{old} - (x^{T}Rx)^{-1}x^{T}(\\hat{y} - t) $ <br>\n","$w^{new} = (x^{T}Rx)^{-1} (x^{T}Rxw^{old} - x^{T}(\\hat{y} - t)) $ <br>\n","$w^{new} = (x^{T}Rx)^{-1}x^{T}Rz$ <br>\n","Where z is an N-dimensional vector with elements <br>\n","$z = xw^{old} - R^{-1}(\\hat{y} - t)$\n","\n","Because the weighing matrix R is not constant but depends on the parameter vector w, we must apply the normal equations iteratively, each time using the new weight vector w to compute a revised weighing matrix R. For this reason, the algorithm is known as iterative reweighted least squares, or IRLS.\n","\n","YOU NEED TO IMPLEMENT an iterative solution to solve for $w$ (IRLS) \n","\n","<font color=\"red\">DO NOT USE SKLEARNS LIBRARY DIRECTLY.</font>"]},{"cell_type":"markdown","metadata":{"id":"PKK499bw-2IT"},"source":["### **Question:** In the following code cell implement the following:\n","* Step 1: Import the dataset using Pandas Dataframe (Step 1 Implemented already)\n","* Step 2: Partition your dataset into training testing and validation using sklearns train_test_split library and split the features and target labels into seperate variables (Step 2 Implemented already)\n","* Step 3: Scale the features using sklearns min max scaling function (Step 3 Implemented already)\n","* Step 4: Convert Scaled Features and Labels into numpy arrays with dimensions required by closed form solution (Step 4 Implemented already)\n","* Step 5: Augment scalend trained, val and test features with unit vectors.(Step 5 Implemented already)\n","* Step 6: Initialize the learning rate, number of epochs, weight vector and other variables required for tracking cost. (Already implemented)\n","* Step 7: Train with Training Dataset using IRLS Solution\n","  Iteratively update the weights and biases for each epoch using:\n","  * Step 7.1: Use genesis equation $\\hat{y} = \\Sigma(W^{T}.X)$ where $W$ is the weight array agumented with bias, $X$ is the input features augmented with unit vector and $\\hat{y}$ is the predicted value. (You will have to perform same operation on validation set as well)\n","  * Step 7.2: Find BCE Cost (L) for training and validation set using predicted value $\\hat{y}$ and truth value $y$\n","    * BCE Cost = $-\\Sigma_{n=1}^{N} [t_{n} \\log {\\hat{y}_{n}} + (1 - t_{n}) \\log {(1 - \\hat{y}_{n}})]$\n","  * Step 7.3: Update $W$ as follows:\n","    - Step 7.3.1: Calculate, $R$ which is a NxN diagonal matrix with diagonal elements $R_{nn} = \\hat{y}_{n}(1 - \\hat{y}_{n})$\n","    - Step 7.3.2: Caculate, $z = w_{old}^{T}x - (\\hat{y} - t)R^{-1}$\n","    - Step 7.3.3: Update, $w^{new} = (xRx^{T})^{-1}xRz^{T}$\n","  * Step 7.4: Store BCE Cost for training and validation in cost tracking lists\n","* Step 8: Plot validation and training cost vs number of epochs (Already Implemented)\n","* Step 9: Test using Testing Dataset\n","  * Step 9.1: Use genesis equation $\\hat{y} = \\sigma (W^{T}.X_{test})$ where $W$ is the augmented weight array, $X_{test}$ is the input test features agumented with unit vector and $\\hat{y}$ is the predicted value.\n","  * Step 9.2: Calculate Accuracy using Sklearns.Metrics library."]},{"cell_type":"code","metadata":{"id":"J2rF2xa1XNqb","executionInfo":{"status":"ok","timestamp":1602784108698,"user_tz":240,"elapsed":617,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}}},"source":["# Step 1 already implemented\n","import pandas as pd\n","import io\n","import requests\n","url=\"https://raw.githubusercontent.com/Mihir2/BreakoutSessionDataset/master/haberman_lr.csv\"\n","s = requests.get(url).content\n","data = pd.read_csv(io.StringIO(s.decode('utf-8')))\n","\n","# Step 2 already implemented\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","output = data['y']\n","input = data.to_numpy()[:,1:]\n","x_train, x_val_test, y_train, y_val_test = train_test_split(input, output, test_size = 0.2)\n","x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size = 0.5)\n","\n","# Step 3 already implemented\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","sc_xtrain = scaler.fit_transform(x_train)\n","sc_xval = scaler.transform(x_val)\n","sc_xtest = scaler.transform(x_test)\n","\n","# Step 4 already implemented\n","augment_xtrain = np.ones((sc_xtrain.shape[0],sc_xtrain.shape[1]+1))\n","augment_xtrain[:,1:] = sc_xtrain\n","\n","augment_xval = np.ones((sc_xval.shape[0],sc_xval.shape[1]+1))\n","augment_xval[:,1:] = sc_xval\n","\n","augment_xtest = np.ones((sc_xtest.shape[0],sc_xtest.shape[1]+1))\n","augment_xtest[:,1:] = sc_xtest\n","\n","# Step 5 already implemented\n","y_train_arr = y_train.to_numpy().reshape(y_train.shape[0],1).T\n","x_train_arr = augment_xtrain.T\n","y_val_arr = y_val.to_numpy().reshape(y_val.shape[0],1).T\n","x_val_arr = augment_xval.T\n","y_test_arr  = y_test.to_numpy().reshape(y_test.shape[0],1).T\n","x_test_arr  = augment_xtest.T\n","\n","# Step 6 already implemented\n","epochs = 100\n","\n","number_of_features         = x_train_arr.shape[0]\n","number_of_train_datapoints = x_train_arr.shape[1]\n","number_of_val_datapoints   = x_val_arr.shape[1]\n","number_of_test_datapoints  = x_test_arr.shape[1]\n","\n","weights = np.random.randn(number_of_features,1)*0.0001\n","\n","training_cost_track = []\n","val_cost_track = []"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uvF76NErYE71"},"source":["### TA Response"]},{"cell_type":"code","metadata":{"id":"mFmi2sp8YEq_","executionInfo":{"status":"ok","timestamp":1602784109327,"user_tz":240,"elapsed":779,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}}},"source":["def sigmoid(z):\n","    return 1 / (1+np.exp(-z))\n","\n","def binary_cross_entropy(pred_y, y, m):\n","    return -np.sum(np.multiply(np.log(pred_y), y) + np.multiply((1-y),np.log(1-pred_y)))/m\n","\n","# Step 7\n","for epoch in range(epochs):\n","    \n","    # Step 7.1 y_pred = \\sigmoid (wT.X + b) (For Training and Validation dataset)\n","    train_pred = sigmoid(np.dot(weights.T, x_train_arr))\n","    val_pred   = sigmoid(np.dot(weights.T, x_val_arr))\n","\n","    # Step 7.2 BCE Cost for Training and Validation Dataset        \n","    train_cost = binary_cross_entropy(train_pred,y_train_arr,number_of_train_datapoints)\n","    val_cost = binary_cross_entropy(val_pred,y_val_arr,number_of_val_datapoints)\n","    \n","    # Step 7.3.1: Calculate R\n","    r_nn = np.multiply(train_pred,(1 - train_pred)).reshape(number_of_train_datapoints,)\n","    R = np.diag(r_nn)\n","    \n","    # Step 7.3.2: Calculate z\n","    z = np.dot(weights.T, x_train_arr) - np.dot((train_pred - y_train_arr),np.linalg.inv(R))\n","\n","    # Step 7.3.2: Calculate w^{new}\n","    weights = np.dot(np.dot(np.dot(np.linalg.inv(np.dot(np.dot(x_train_arr,R),x_train_arr.T)),x_train_arr),R),z.T)\n","\n","    # Step 7.4: Store perceptron cost for training and validation in seperate cost tracking list\n","    training_cost_track.append(train_cost)\n","    val_cost_track.append(val_cost)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TyNUITCtYEdR"},"source":["### Student Response"]},{"cell_type":"code","metadata":{"id":"OWMTH_h4XktM"},"source":["# Step 7\n","\n","def sigmoid(z):\n","  return 1/(1+np.exp(-z))\n","for epoch in range(epochs):\n","    \n","    # Step 7.1 y_pred = \\sigmoid (wT.X + b) (For Training and Validation dataset)\n","    train_pred = sigmoid(np.dot(weights.T,x_train_arr))\n","    val_pred   = sigmoid(np.dot(weights.T,x_val_arr))\n","\n","    # Step 7.2 BCE Cost for Training and Validation Dataset        \n","    train_cost = -np.sum(y_train_arr*np.log(train_pred) + (1-y_train_arr)*np.log(1-train_pred))\n","    val_cost = -np.sum(y_val_arr*np.log(val_pred) + (1-y_val_arr)*np.log(1-val_pred))\n","    \n","    # Step 7.3.1: Calculate R\n","    r = train_pred*(1-train_pred)\n","    R = np.diag(r.flatten())\n","    #print (R.shape)\n","    # Step 7.3.2: Calculate z\n","    R_inv = np.linalg.inv(R)\n","    z = np.dot(weights.T,x_train_arr) - np.dot((train_pred - y_train_arr),R_inv)\n","\n","    # Step 7.3.2: Calculate w^{new} (xRxT)−1xRzT / \n","    xT = x_train_arr.T\n","    xR = np.dot(x_train_arr, R)\n","    b = np.dot(xR,xT)\n","    b_inv = np.linalg.inv(b)\n","    rzt = np.dot(np.dot(x_train_arr,R), z.T)\n","    weights = np.dot(b_inv,rzt)\n","\n","    # Step 7.4: Store perceptron cost for training and validation in seperate cost tracking list\n","    training_cost_track.append(train_cost)\n","    val_cost_track.append(val_cost)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqaJ5BeMXnjl","executionInfo":{"status":"ok","timestamp":1602784112688,"user_tz":240,"elapsed":516,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}},"outputId":"0ab3364e-336d-41bd-e60a-60646415a252","colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["# Step 7: Plot MSE cost for training and validation set vs number of epochs (Already Implemented)\n","import matplotlib.pyplot as plt\n","plt.title('Training and Validation Loss')\n","plt.plot(training_cost_track, color='red', label='Training Data')\n","plt.plot(val_cost_track, color='blue', label='Validation Data')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"FrnHUM8KXqQj","executionInfo":{"status":"ok","timestamp":1602784114466,"user_tz":240,"elapsed":364,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}},"outputId":"1b5b0797-b9a7-48fa-8956-6bdfd836e923","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Step 9.1: Test using Testing Dataset: Get the predicted values \n","test_pred = sigmoid(np.dot(weights.T,x_test_arr))\n","test_pred = np.where(test_pred > 0.5, 1, 0)\n","# Step 9.2 Calculate the Accuracy for Testing Dataset\n","from sklearn.metrics import accuracy_score\n","print (accuracy_score(y_test_arr.flatten(),test_pred.flatten()))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["0.8709677419354839\n"],"name":"stdout"}]}]}