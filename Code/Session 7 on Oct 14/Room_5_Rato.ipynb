{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Room_5_Rato.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fNaFHpTB97qG"},"source":["# List Full Names of all the participants in your team below:\n","1. Tulika Sharma\n","2. Mayank Lara\n","3. Vibhav Yawalkar\n","4. Nick Anzalone\n","5. Anthony Bhasin\n","6. Yuan Meng\n","7. Gaurav Toravane\n","8. Yinxia Chen\n","9. Edmund Wu\n","10. \n","11. "]},{"cell_type":"markdown","metadata":{"id":"r9soxefA_B1l"},"source":["Hello Machine Learning Engineer Rato Team, \n","\n","You have been given a **Titanic Survival Dataset**. The sinking of the Titanic is one of the most infamous shipwrecks in history. \n","\n","Number of Instances: 712 <br>\n","Number of Attributes: 8 (including the target variable `y`)\n","\n","Attribute Information: \n","\n","* **y**  Survival\n","    * -1 = No\n","    * 1 = Yes\n","* **f1** Passenger class\n","    * 1 = 1st class\n","    * 2 = 2nd class\n","    * 3 = 3rd class\n","* **f2** Sex\n","    * 0 = Male\n","    * 1 = Female\n","* **f3** Age in years\n","* **f4** # of siblings / spouses aboard the Titanic\n","* **f5** # of parents / children aboard the Titanic\n","* **f6** Passenger Fare\n","* **f7** Port of Embarkation\n","    * 0 = Southampton\n","    * 1 = Cherbourg\n","    * 2 = Queenstown\n","\n","There are no missing Attribute Values.\n","\n","Your task is to implement a **Iterative Reweighted Least Squares appraoch for Logistic Regression** to predict if the passenger on Titanic Survived or not."]},{"cell_type":"markdown","metadata":{"id":"jiN_JTrt_HgH"},"source":["\n","## Iterative reweighted least squares\n","The **Genesis Equation** for Logistic Regression Model is of the form:\n","\n","$\\hat{y}(x,w) = \\sigma (w^{T}.x)$  <br>\n","\n","* $\\hat{y}(x,w)$ is predicted output,\n","* $x$ is the aumented Input (augmented with unit vector column)\n","* $w = [w_{0}, w_{1}, w_{2}, .. , w_{F}]$ are the parameters to be learned from training samples with $F$ Features\n","* $t_{n}$ is the target variable (truth label)\n","\n","The **Loss Function** for Logistic Regression Model is of the form: <br>\n","\n","$E(w) = -\\Sigma_{n=1}^{N} [t_{n} \\log {\\hat{y}_{n}} + (1 - t_{n}) \\log {(1 - \\hat{y}_{n}})]$\n","\n","The **Newton-Raphson update**, for minimizing a function E(w), takes the form\n","\n","$w^{new} = w^{old} - H^{-1} \\Delta E(w) $ <br>\n","Where H is the Hessian matrix whose elements comprise the second derivative with respect to the components of w.\n","\n","Applying the Newton-Raphson update to the binary-cross-entropy error function\n","for the logistic regression model. We see that the gradient and\n","Hessian of this error function are given by: <br>\n","\n","$\\Delta E(w) = \\Sigma^{N}_{n = 1} (\\hat{y}_{n} - t_{n})x_{n} = x^{T} (\\hat{y} - t)$ <br>\n","\n","$H = \\Delta \\Delta E(w) = \\Sigma^{N}_{n = 1} \\hat{y}_{n}(1 - \\hat{y}_{n})x_{n}x_{n}^{T} = x^{T}Rx$\n","\n","Where $R$ is a NxN diagonal matrix with elements $R_{nn} = \\hat{y}_{n}(1 - \\hat{y}_{n})$\n","\n","The Newton-Raphson update formula for the logistic regression model then becomes: <br>\n","$w^{new} = w^{old} - (x^{T}Rx)^{-1}x^{T}(\\hat{y} - t) $ <br>\n","$w^{new} = (x^{T}Rx)^{-1} (x^{T}Rxw^{old} - x^{T}(\\hat{y} - t)) $ <br>\n","$w^{new} = (x^{T}Rx)^{-1}x^{T}Rz$ <br>\n","Where z is an N-dimensional vector with elements <br>\n","$z = xw^{old} - R^{-1}(\\hat{y} - t)$\n","\n","Because the weighing matrix R is not constant but depends on the parameter vector w, we must apply the normal equations iteratively, each time using the new weight vector w to compute a revised weighing matrix R. For this reason, the algorithm is known as iterative reweighted least squares, or IRLS.\n","\n","YOU NEED TO IMPLEMENT an iterative solution to solve for $w$ (IRLS) \n","\n","<font color=\"red\">DO NOT USE SKLEARNS LIBRARY DIRECTLY.</font>"]},{"cell_type":"markdown","metadata":{"id":"SKuCBMss_LCe"},"source":["### **Question:** In the following code cell implement the following:\n","* Step 1: Import the dataset using Pandas Dataframe (Step 1 Implemented already)\n","* Step 2: Partition your dataset into training testing and validation using sklearns train_test_split library and split the features and target labels into seperate variables (Step 2 Implemented already)\n","* Step 3: Scale the features using sklearns min max scaling function (Step 3 Implemented already)\n","* Step 4: Convert Scaled Features and Labels into numpy arrays with dimensions required by closed form solution (Step 4 Implemented already)\n","* Step 5: Augment scalend trained, val and test features with unit vectors.(Step 5 Implemented already)\n","* Step 6: Initialize the learning rate, number of epochs, weight vector and other variables required for tracking cost. (Already implemented)\n","* Step 7: Train with Training Dataset using IRLS Solution\n","  Iteratively update the weights and biases for each epoch using:\n","  * Step 7.1: Use genesis equation $\\hat{y} = \\Sigma(W^{T}.X)$ where $W$ is the weight array agumented with bias, $X$ is the input features augmented with unit vector and $\\hat{y}$ is the predicted value. (You will have to perform same operation on validation set as well)\n","  * Step 7.2: Find BCE Cost (L) for training and validation set using predicted value $\\hat{y}$ and truth value $y$\n","    * BCE Cost = $-\\Sigma_{n=1}^{N} [t_{n} \\log {\\hat{y}_{n}} + (1 - t_{n}) \\log {(1 - \\hat{y}_{n}})]$\n","  * Step 7.3: Update $W$ as follows:\n","    - Step 7.3.1: Calculate, $R$ which is a NxN diagonal matrix with diagonal elements $R_{nn} = \\hat{y}_{n}(1 - \\hat{y}_{n})$\n","    - Step 7.3.2: Caculate, $z = w_{old}^{T}x - (\\hat{y} - t)R^{-1}$\n","    - Step 7.3.3: Update, $w^{new} = (xRx^{T})^{-1}Rz^{T}$\n","  * Step 7.4: Store BCE Cost for training and validation in cost tracking lists\n","* Step 8: Plot validation and training cost vs number of epochs (Already Implemented)\n","* Step 9: Test using Testing Dataset\n","  * Step 9.1: Use genesis equation $\\hat{y} = \\sigma (W^{T}.X_{test})$ where $W$ is the augmented weight array, $X_{test}$ is the input test features agumented with unit vector and $\\hat{y}$ is the predicted value.\n","  * Step 9.2: Calculate Accuracy using Sklearns.Metrics library."]},{"cell_type":"code","metadata":{"id":"qUDTxaC1ZHvs","executionInfo":{"status":"ok","timestamp":1602784182626,"user_tz":240,"elapsed":550,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}}},"source":["# Step 1 already implemented\n","import pandas as pd\n","import io\n","import requests\n","url=\"https://raw.githubusercontent.com/Mihir2/BreakoutSessionDataset/master/titanic_lr.csv\"\n","s = requests.get(url).content\n","data = pd.read_csv(io.StringIO(s.decode('utf-8')))\n","\n","# Step 2 already implemented\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","output = data['y']\n","input = data.to_numpy()[:,1:]\n","x_train, x_val_test, y_train, y_val_test = train_test_split(input, output, test_size = 0.2)\n","x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size = 0.5)\n","\n","# Step 3 already implemented\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","sc_xtrain = scaler.fit_transform(x_train)\n","sc_xval = scaler.transform(x_val)\n","sc_xtest = scaler.transform(x_test)\n","\n","# Step 4 already implemented\n","augment_xtrain = np.ones((sc_xtrain.shape[0],sc_xtrain.shape[1]+1))\n","augment_xtrain[:,1:] = sc_xtrain\n","\n","augment_xval = np.ones((sc_xval.shape[0],sc_xval.shape[1]+1))\n","augment_xval[:,1:] = sc_xval\n","\n","augment_xtest = np.ones((sc_xtest.shape[0],sc_xtest.shape[1]+1))\n","augment_xtest[:,1:] = sc_xtest\n","\n","# Step 5 already implemented\n","y_train_arr = y_train.to_numpy().reshape(y_train.shape[0],1).T\n","x_train_arr = augment_xtrain.T\n","y_val_arr = y_val.to_numpy().reshape(y_val.shape[0],1).T\n","x_val_arr = augment_xval.T\n","y_test_arr  = y_test.to_numpy().reshape(y_test.shape[0],1).T\n","x_test_arr  = augment_xtest.T\n","\n","# Step 6 already implemented\n","epochs = 100\n","\n","number_of_features         = x_train_arr.shape[0]\n","number_of_train_datapoints = x_train_arr.shape[1]\n","number_of_val_datapoints   = x_val_arr.shape[1]\n","number_of_test_datapoints  = x_test_arr.shape[1]\n","\n","weights = np.random.randn(number_of_features,1)*0.001\n","\n","training_cost_track = []\n","val_cost_track = []"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HS7bmbGaYTWg"},"source":["### TA Response"]},{"cell_type":"code","metadata":{"id":"oRFi1h1WYTER","executionInfo":{"status":"ok","timestamp":1602784186460,"user_tz":240,"elapsed":3881,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}}},"source":["def sigmoid(z):\n","    return 1 / (1+np.exp(-z))\n","\n","def binary_cross_entropy(pred_y, y, m):\n","    return -np.sum(np.multiply(np.log(pred_y), y) + np.multiply((1-y),np.log(1-pred_y)))/m\n","\n","# Step 7\n","for epoch in range(epochs):\n","    \n","    # Step 7.1 y_pred = \\sigmoid (wT.X + b) (For Training and Validation dataset)\n","    train_pred = sigmoid(np.dot(weights.T, x_train_arr))\n","    val_pred   = sigmoid(np.dot(weights.T, x_val_arr))\n","\n","    # Step 7.2 BCE Cost for Training and Validation Dataset        \n","    train_cost = binary_cross_entropy(train_pred,y_train_arr,number_of_train_datapoints)\n","    val_cost = binary_cross_entropy(val_pred,y_val_arr,number_of_val_datapoints)\n","    \n","    # Step 7.3.1: Calculate R\n","    r_nn = np.multiply(train_pred,(1 - train_pred)).reshape(number_of_train_datapoints,)\n","    R = np.diag(r_nn)\n","    \n","    # Step 7.3.2: Calculate z\n","    z = np.dot(weights.T, x_train_arr) - np.dot((train_pred - y_train_arr),np.linalg.inv(R))\n","\n","    # Step 7.3.2: Calculate w^{new}\n","    weights = np.dot(np.dot(np.dot(np.linalg.inv(np.dot(np.dot(x_train_arr,R),x_train_arr.T)),x_train_arr),R),z.T)\n","\n","    # Step 7.4: Store perceptron cost for training and validation in seperate cost tracking list\n","    training_cost_track.append(train_cost)\n","    val_cost_track.append(val_cost)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HbLBi0I3YTjE"},"source":["### Student Response"]},{"cell_type":"code","metadata":{"id":"lbyAMjklRRSV"},"source":["def sigmoid(z):\n","  return 1/(1+np.exp(-z))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0FmI9Io7ZR05"},"source":["# Step 7\n","from numpy.linalg import inv\n","for epoch in range(epochs):\n","    \n","    # Step 7.1 y_pred = \\sigmoid (wT.X + b) (For Training and Validation dataset)\n","    y_pred = np.dot(weights.T,x_train_arr) \n","    y_pred_val = np.dot(weights.T,x_val_arr) \n","    train_pred = sigmoid(y_pred)\n","    val_pred   = sigmoid(y_pred_val)\n","\n","    # Step 7.2 BCE Cost for Training and Validation Dataset        \n","    train_cost = -np.sum(y_train_arr*np.log(train_pred) + (1-y_train_arr)*np.log(1-train_pred))\n","    val_cost = -np.sum(y_val_arr*np.log(val_pred) + (1-y_val_arr)*np.log(1-val_pred))\n","    \n","    # Step 7.3.1: Calculate R\n","    R = np.diag(np.multiply(train_pred,(1-train_pred)).flatten())\n","    \n","    # Step 7.3.2: Calculate z\n","    v=np.dot((train_pred-y_train_arr),inv(R))\n","    z = np.dot(weights.T,x_train_arr) - v\n","\n","    # Step 7.3.2: Calculate w^{new}\n","    b_inv=inv(np.dot(np.dot(x_train_arr,R),x_train_arr.T))\n","    rv=np.dot(np.dot(x_train_arr,R),z.T)\n","    weights = np.dot(b_inv,rv)\n","\n","    # Step 7.4: Store perceptron cost for training and validation in seperate cost tracking list\n","    training_cost_track.append(train_cost)\n","    val_cost_track.append(val_cost) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2uztZmjZUTY","executionInfo":{"status":"ok","timestamp":1602784188805,"user_tz":240,"elapsed":490,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}},"outputId":"2185050f-84ab-4682-e274-2adafccdb53a","colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["# Step 7: Plot MSE cost for training and validation set vs number of epochs (Already Implemented)\n","import matplotlib.pyplot as plt\n","plt.title('Training and Validation Loss')\n","plt.plot(training_cost_track, color='red', label='Training Data')\n","plt.plot(val_cost_track, color='blue', label='Validation Data')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Chl84f38ZX5Z","executionInfo":{"status":"ok","timestamp":1602784193683,"user_tz":240,"elapsed":679,"user":{"displayName":"Mihir Hemant Chauhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilYoSLpXB8B3bEittwsBFYECo7WO6QjgO2KEdR=s64","userId":"14043489589883647341"}},"outputId":"b7e9d7b3-8dfd-455f-c8a1-66c8f4760e57","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Step 9.1: Test using Testing Dataset: Get the predicted values \n","test_pred = np.dot(weights.T,x_test_arr)\n","y_test_pred= sigmoid(test_pred)\n","threshold=np.where(y_test_pred >= 0.5, 1, 0)\n","\n","# Step 9.2 Calculate the Accuracy for Testing Dataset\n","from sklearn.metrics import accuracy_score\n","print(accuracy_score(y_test_arr.flatten(), threshold.flatten()))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["0.7916666666666666\n"],"name":"stdout"}]}]}