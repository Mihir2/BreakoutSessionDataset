{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Room_4_Jokang.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Jm71MEiDi659","colab_type":"text"},"source":["Hello Machine Learning Engineer Jokang Team, \n","\n","You have been given a data which is obtained from **House Prices** in Buffalo, City. \n","\n","Number of Instances: 414 <br>\n","Number of Attributes: 5 (including the target variable `y`)\n","\n","Attribute Information: \n","  * **y**: Value of the house of unit area in $\n","  * **f1**: the house age (unit: year)\n","  * **f2**: the distance to the nearest MRT station (unit: meter)\n","  * **f3**: the number of convenience stores in the living circle on foot (integer)\n","  * **f4**: the geographic coordinate, latitude. (unit: degree)\n","  * **f5**: the geographic coordinate, longitude. (unit: degree)\n","\n","\n","There are no missing Attribute Values.\n","\n","Based on the features mentioned above, your task is to build a Liner Regression Model to predict the house price in Buffalo\n","\n","## Closed Form Solution\n","The genesis equation for Linear Regression model is of the form:\n","\n","$y = X.W$  where; <br>\n","$Y$ is output, <br>\n","$W$ are the parameters and <br>\n"," $T$ is the Target\n","\n","For finding parameters $W$ for the above genesis using the **closed form solution** we pre-multiply by $X^{-1}$ on LHS and RHS. We get,\n","\n","$W = X^{-1}Y$\n","\n","But X is NOT A SQUARE MATRIX of FULL RANK! Hence, $X^{-1}$ is intractable.\n","\n","We therefore use the Moore-Penrose pseudo inverse as a generalization of the matrix inverse when the matrix may not be invertible. Hence, the final closed form solution for finding parameters $W$ with linear regression least squares solution is as follows:\n","\n","$W = (X^{T}X)^{-1}X^{T}Y$\n","\n","\n","\n","YOU NEED TO IMPLEMENT ABOVE EQUATION for finding $W$. \n","\n","<font color=\"red\"> YOU CANNOT USE NUMPY linalg **pinv** https://numpy.org/doc/stable/reference/generated/numpy.linalg.pinv.html </font>\n","\n","<font color=\"red\">DO NOT USE SKLEARNS LINEAR REGRESSION LIBRARY DIRECTLY.</font>\n","\n","\n","<font color=\"green\">YOU CAN USE np.linalg.inv, and np.dot FOR IMPLEMENTING PSEUDO-INVERSE</font>\n"]},{"cell_type":"markdown","metadata":{"id":"qBbYTZa_l93K","colab_type":"text"},"source":["### **Question:** In the following code cell implement the following:\n","* Step 1: Import the dataset (HousePriceBuffalo.csv) using Pandas Dataframe (Step 1 Implemented already)\n","* Step 2: Partition your dataset into training testing and validation using sklearns train_test_split library and split the features and target labels into seperate variables (Step 2 Implemented already)\n","* Step 3: Scale the features using sklearns min max scaling function (Step 3 Implemented already)\n","* Step 4: Convert Scaled Features and Labels into numpy arrays with dimensions required by closed form solution (Step 4 Implemented already)\n","* Step 5: Train using Linear Regression algorithm with a Closed Form Solution **Hint: Use Pseudo Inverse Formula**\n","* Step 6: Test using Testing Dataset\n","* Step 7: Calculate Root Mean Squared Error for Test Dataset\n","    * $Erms = \\frac{1}{n}\\sqrt{(y\\_test - y\\_test\\_pred)^{2}}$ "]},{"cell_type":"code","metadata":{"id":"E8a_sw3riu9l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600297687408,"user_tz":240,"elapsed":426,"user":{"displayName":"Gaurav Ravindra Toravane","photoUrl":"","userId":"03834369426800348659"}},"outputId":"c4e106be-c045-4c57-873c-679bd9b52874"},"source":["# Step 1 already implemented\n","import pandas as pd\n","import io\n","import requests\n","url=\"https://raw.githubusercontent.com/Mihir2/BreakoutSessionDataset/master/HousePriceBuffalo.csv\"\n","s = requests.get(url).content\n","data = pd.read_csv(io.StringIO(s.decode('utf-8')))\n","data\n","\n","# Step 2 already implemented\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","output = data['y']\n","input = data.to_numpy()[:,1:]\n","x_train, x_test, y_train, y_test = train_test_split(input, output, test_size = 0.2)\n","\n","# Step 3 already implemented\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","sc_xtrain = scaler.fit_transform(x_train)\n","sc_xtest = scaler.transform(x_test)\n","\n","# Step 4 already implemented\n","y_train_arr = y_train.to_numpy().reshape(y_train.shape[0],1)\n","x_train_arr = sc_xtrain\n","y_test_arr  = y_test.to_numpy().reshape(y_test.shape[0],1)\n","x_test_arr  = sc_xtest\n","\n","# Step 5\n","x_transpose = np.matrix.transpose(x_train_arr)\n","x_transpose_x = np.dot(x_transpose, x_train_arr)\n","\n","x_transpose_y = np.dot(x_transpose, y_train_arr)\n","\n","x_transpose_x_inverse = np.linalg.inv(x_transpose_x)\n","\n","w = np.dot(x_transpose_x_inverse,x_transpose_y)\n","# Step 6\n","y_test_pred = np.dot(x_test_arr,w)\n","\n","\n","# Step 7\n","sub = (y_test_arr - y_test_pred)\n","sub = sub **2\n","sub_square = np.sum(sub) \n","erms = np.sqrt(sub_square) /414\n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, 1)"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"JlSZC8XjIbK3","colab_type":"code","colab":{}},"source":["3"],"execution_count":null,"outputs":[]}]}